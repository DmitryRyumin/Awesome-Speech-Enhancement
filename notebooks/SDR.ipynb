{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d11f6359-c4f0-425d-9cbb-eb655e387bff",
   "metadata": {},
   "source": [
    "## SDR: Signal-to-Distortion Ratio\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e026b0-1527-49fc-ad74-187886c16214",
   "metadata": {},
   "source": [
    "### Version of Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f36d3b68-51d7-4f03-8fcf-d7564222dd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.11\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e375933-a493-49da-8f23-e762f1dcf95a",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b118844f-79a1-4a72-9f59-2debacf3b9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression of warnings\n",
    "import warnings\n",
    "for warn in [UserWarning, FutureWarning]: warnings.filterwarnings('ignore', category = warn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "babc8246-91c7-4e6f-a4f6-a8cba52f542f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import jupyterlab as jlab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8544445-a738-4704-afd8-cce404d5a24b",
   "metadata": {},
   "source": [
    "### Versions of required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92b1f76b-f8dc-4ed0-a739-2491beeb170e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Package</th>\n",
       "      <th>Version</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PyTorch</td>\n",
       "      <td>2.2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TorchAudio</td>\n",
       "      <td>2.2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TorchMetrics</td>\n",
       "      <td>1.3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NumPy</td>\n",
       "      <td>1.26.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pandas</td>\n",
       "      <td>2.2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Matplotlib</td>\n",
       "      <td>3.8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JupyterLab</td>\n",
       "      <td>4.1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Package Version\n",
       "No                      \n",
       "1        PyTorch   2.2.1\n",
       "2     TorchAudio   2.2.1\n",
       "3   TorchMetrics   1.3.2\n",
       "4          NumPy  1.26.4\n",
       "5         Pandas   2.2.1\n",
       "6     Matplotlib   3.8.3\n",
       "7     JupyterLab   4.1.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pkgs = {\n",
    "    'Package': [\n",
    "        'PyTorch', 'TorchAudio', 'TorchMetrics', 'NumPy', 'Pandas', 'Matplotlib', 'JupyterLab'\n",
    "    ],\n",
    "    'Version': [i.__version__ for i in [\n",
    "        torch, torchaudio, torchmetrics, np, pd, matplotlib, jlab\n",
    "    ]]\n",
    "}\n",
    "\n",
    "df_pkgs = pd.DataFrame(data = pkgs)\n",
    "df_pkgs.index.name = 'No'\n",
    "df_pkgs.index += 1\n",
    "\n",
    "display(df_pkgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c5414c-59b8-4b19-89f0-5f258afa6069",
   "metadata": {},
   "source": [
    "### SDR: Signal-to-Distortion Ratio (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6341e064-8619-411b-acd8-b8c4af4838f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal-to-Distortion Ratio (SDR): 13.61730 dB\n"
     ]
    }
   ],
   "source": [
    "# Path to clean and noisy speech signals\n",
    "clean_speech_path = 'DS_10283_2791/clean_trainset_56spk_wav/p234_001.wav'\n",
    "noisy_speech_path = 'DS_10283_2791/noisy_trainset_56spk_wav/p234_001.wav'\n",
    "\n",
    "# Load clean and noisy speech signals\n",
    "clean_speech, sample_rate = torchaudio.load(clean_speech_path)\n",
    "noisy_speech, _ = torchaudio.load(noisy_speech_path)\n",
    "\n",
    "# Ensure clean and noisy signals have the same length\n",
    "assert clean_speech.shape == noisy_speech.shape, \"Clean and noisy signal tensors must have the same shape\"\n",
    "\n",
    "# Compute SDR\n",
    "sdr = torchmetrics.audio.SignalDistortionRatio(filter_length = 512)(noisy_speech, clean_speech)\n",
    "\n",
    "# Print result\n",
    "print(f'Signal-to-Distortion Ratio (SDR): {sdr:.5f} dB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c66c7f5-0116-4c82-afc0-6b0cdce447f3",
   "metadata": {},
   "source": [
    "### SDR: Signal-to-Distortion Ratio (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1bf689b-0476-43c5-a2be-458384f6eef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal-to-Distortion Ratio (SDR): 13.61730 dB\n"
     ]
    }
   ],
   "source": [
    "def compute_sdr(clean_signal, noisy_signal, filter_length=512):\n",
    "    \"\"\"\n",
    "    Compute the Signal-to-Distortion Ratio (SDR) between a clean and noisy signal.\n",
    "\n",
    "    Args:\n",
    "        clean_signal (torch.Tensor): The clean signal tensor.\n",
    "        noisy_signal (torch.Tensor): The noisy signal tensor.\n",
    "        filter_length (int): The length of the filter used for computing SDR.\n",
    "\n",
    "    Returns:\n",
    "        float: The computed Signal-to-Distortion Ratio (SDR) in decibels (dB).\n",
    "    \"\"\"\n",
    "\n",
    "    assert clean_signal.shape == noisy_signal.shape, \"Clean and noisy signal tensors must have the same shape\"\n",
    "\n",
    "    # Convert to double precision if necessary\n",
    "    if clean_signal.dtype != torch.float64:\n",
    "        clean_signal = clean_signal.double()\n",
    "    if noisy_signal.dtype != torch.float64:\n",
    "        noisy_signal = noisy_signal.double()\n",
    "\n",
    "    # Normalize tensors\n",
    "    clean_signal /= torch.clamp(torch.norm(clean_signal, dim=-1, keepdim=True), min=1e-6)\n",
    "    noisy_signal /= torch.clamp(torch.norm(noisy_signal, dim=-1, keepdim=True), min=1e-6)\n",
    "\n",
    "    n_fft = 2 ** math.ceil(math.log2(noisy_signal.shape[-1] + clean_signal.shape[-1] - 1))\n",
    "\n",
    "    # Compute auto-correlation of clean_signal\n",
    "    t_fft_clean = torch.fft.rfft(clean_signal, n=n_fft, dim=-1)\n",
    "    r_0 = torch.fft.irfft(t_fft_clean.real**2 + t_fft_clean.imag**2, n=n_fft)[..., :filter_length]\n",
    "\n",
    "    # Compute cross-correlation of clean_signal and noisy_signal\n",
    "    p_fft_noisy = torch.fft.rfft(noisy_signal, n=n_fft, dim=-1)\n",
    "    b = torch.fft.irfft(t_fft_clean.conj() * p_fft_noisy, n=n_fft, dim=-1)[..., :filter_length]\n",
    "\n",
    "    # Compute symmetric Toeplitz matrix\n",
    "    vec_exp = torch.cat([torch.flip(r_0, dims=(-1,)), r_0[..., 1:]], dim=-1)\n",
    "    v_len = r_0.shape[-1]\n",
    "    symmetric_toeplitz = torch.as_strided(\n",
    "        vec_exp, size=vec_exp.shape[:-1] + (v_len, v_len), stride=vec_exp.stride()[:-1] + (1, 1)\n",
    "    ).flip(dims=(-1,))\n",
    "\n",
    "    # Solve for the optimal filter\n",
    "    sol = torch.linalg.solve(symmetric_toeplitz, b)\n",
    "\n",
    "    # Compute the coherence\n",
    "    coh = torch.einsum(\"...l,...l->...\", b, sol)\n",
    "\n",
    "    # Transform to decibels\n",
    "    ratio = coh / (1 - coh)\n",
    "    sdr = 10.0 * torch.log10(ratio)\n",
    "\n",
    "    return sdr.squeeze()\n",
    "\n",
    "# Path to clean and noisy speech signals\n",
    "clean_speech_path = 'DS_10283_2791/clean_trainset_56spk_wav/p234_001.wav'\n",
    "noisy_speech_path = 'DS_10283_2791/noisy_trainset_56spk_wav/p234_001.wav'\n",
    "\n",
    "# Load clean and noisy speech signals\n",
    "clean_speech, _ = torchaudio.load(clean_speech_path)\n",
    "noisy_speech, _ = torchaudio.load(noisy_speech_path)\n",
    "\n",
    "# Compute SDR\n",
    "sdr = compute_sdr(clean_speech, noisy_speech, 512)\n",
    "\n",
    "# Print result\n",
    "print(f'Signal-to-Distortion Ratio (SDR): {sdr:.5f} dB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
